{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\python311\\lib\\site-packages (4.11.0.86)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\python311\\lib\\site-packages (from opencv-python) (2.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: numpy in c:\\python311\\lib\\site-packages (2.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: matplotlib in c:\\python311\\lib\\site-packages (3.9.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\python311\\lib\\site-packages (from matplotlib) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\python311\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\python311\\lib\\site-packages (from matplotlib) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\python311\\lib\\site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\python311\\lib\\site-packages (from matplotlib) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\asus\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\python311\\lib\\site-packages (from matplotlib) (10.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\python311\\lib\\site-packages (from matplotlib) (3.1.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\asus\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\asus\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install opencv-python\n",
    "%pip install numpy\n",
    "%pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import shutil\n",
    "import imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_black_borders(img): \n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    _, thresh = cv2.threshold(gray, 1, 255, cv2.THRESH_BINARY)\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if contours:\n",
    "        max_contour = max(contours, key=cv2.contourArea)\n",
    "        x, y, w, h = cv2.boundingRect(max_contour)\n",
    "        return img[y:y+h, x:x+w]\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_keypoints(image, keypoints):\n",
    "    return cv2.drawKeypoints(image, keypoints, None, color=(0, 255, 0), flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_matches(img1, kp1, img2, kp2, matches):\n",
    "    return cv2.drawMatches(img1, kp1, img2, kp2, matches, None, matchColor=(0, 255, 0), singlePointColor=(255, 0, 0),flags=cv2.DrawMatchesFlags_DEFAULT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keypoints(images):\n",
    "    sift = cv2.SIFT_create(nfeatures=2000, contrastThreshold=0.04)\n",
    "    keypoints_descriptors = []\n",
    "    \n",
    "    for i, img in enumerate(images):\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        kp, des = sift.detectAndCompute(gray, None)\n",
    "        keypoints_descriptors.append((kp, des))\n",
    "        \n",
    "        # Save image with keypoints\n",
    "        cv2.imwrite(os.path.join(\"PanoOutputs/Pano_Keypoints/\", f\"image_{i+1}_with_keypoints.jpg\"), draw_keypoints(img.copy(), kp))\n",
    "        \n",
    "    return keypoints_descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stitch_images_sequential(images, keypoints_descriptors):\n",
    "    matcher = cv2.BFMatcher(cv2.NORM_L2)\n",
    "    \n",
    "    if len(images) < 2:\n",
    "        return images[0]\n",
    "    \n",
    "    result = images[0]\n",
    "    \n",
    "    for i in range(1, len(images)):\n",
    "        print(f\"Stitching image {i+1}/{len(images)}\")\n",
    "        \n",
    "        img1 = result\n",
    "        img2 = images[i]\n",
    "        \n",
    "        # Recompute keypoints for current result\n",
    "        sift = cv2.SIFT_create(nfeatures=2000, contrastThreshold=0.04)\n",
    "        kp1, des1 = sift.detectAndCompute(cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY), None)\n",
    "        \n",
    "        # Get keypoints for the next image\n",
    "        kp2, des2 = keypoints_descriptors[i]\n",
    "        \n",
    "        # Match features\n",
    "        matches = matcher.knnMatch(des2, des1, k=2)\n",
    "        \n",
    "        # Filter good matches\n",
    "        good_matches = [m for m, n in matches if m.distance < 0.75 * n.distance]\n",
    "        \n",
    "        # Save match visualization\n",
    "        match_img = draw_matches(img2, kp2, img1, kp1, good_matches)\n",
    "        cv2.imwrite(os.path.join(\"PanoOutputs/Pano_Keypoint_Matches\", f\"matches_{i}_to_{i+1}.jpg\"), match_img)\n",
    "\n",
    "        # Not enough matches for stiching\n",
    "        \n",
    "        if len(good_matches) < 10:\n",
    "            continue\n",
    "        \n",
    "        # Get matching points\n",
    "        src_pts = np.float32([kp2[m.queryIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
    "        dst_pts = np.float32([kp1[m.trainIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
    "        \n",
    "        # Find homography\n",
    "        H, _ = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0, maxIters=2000)\n",
    "\n",
    "        # Could not find Homography so skipping the image\n",
    "        if H is None:\n",
    "            continue\n",
    "        \n",
    "        # Get dimensions\n",
    "        h1, w1 = img1.shape[:2]\n",
    "        h2, w2 = img2.shape[:2]\n",
    "        \n",
    "        # Find transformed corners of img2\n",
    "        corners = np.array([[0, 0], [0, h2-1], [w2-1, h2-1], [w2-1, 0]], dtype=np.float32).reshape(-1, 1, 2)\n",
    "        corners_transformed = cv2.perspectiveTransform(corners, H)\n",
    "        \n",
    "        # Calculate canvas size\n",
    "        [xmin, ymin] = np.int32(corners_transformed.min(axis=0).ravel() - 0.5)\n",
    "        [xmax, ymax] = np.int32(corners_transformed.max(axis=0).ravel() + 0.5)\n",
    "        \n",
    "        # Handle negative offsets\n",
    "        xmin_offset = abs(min(xmin, 0))\n",
    "        ymin_offset = abs(min(ymin, 0))\n",
    "        \n",
    "        # Create translation matrix\n",
    "        translation_matrix = np.array([\n",
    "            [1, 0, xmin_offset],\n",
    "            [0, 1, ymin_offset],\n",
    "            [0, 0, 1]\n",
    "        ])\n",
    "        \n",
    "        # Apply translation to homography\n",
    "        H_adjusted = translation_matrix @ H\n",
    "        \n",
    "        # Create panorama canvas\n",
    "        panorama_width = max(xmax + xmin_offset, w1 + xmin_offset) + 100\n",
    "        panorama_height = max(ymax + ymin_offset, h1 + ymin_offset) + 100\n",
    "        \n",
    "        panorama = np.zeros((panorama_height, panorama_width, 3), dtype=np.uint8)\n",
    "        \n",
    "        # Warp second image\n",
    "        warped_img = cv2.warpPerspective(img2, H_adjusted, (panorama_width, panorama_height))\n",
    "        \n",
    "        # Create masks\n",
    "        warped_mask = cv2.warpPerspective(np.ones((h2, w2), dtype=np.uint8) * 255, H_adjusted, (panorama_width, panorama_height))\n",
    "        \n",
    "        # Place first image\n",
    "        panorama[ymin_offset:ymin_offset+h1, xmin_offset:xmin_offset+w1] = img1\n",
    "        \n",
    "        # Create first image mask\n",
    "        first_image_mask = np.zeros((panorama_height, panorama_width), dtype=np.uint8)\n",
    "        first_image_mask[ymin_offset:ymin_offset+h1, xmin_offset:xmin_offset+w1] = 255\n",
    "        \n",
    "        # Find overlap\n",
    "        overlap = cv2.bitwise_and(first_image_mask, warped_mask)\n",
    "        \n",
    "        # Create weight maps\n",
    "        weight_map1 = cv2.distanceTransform(first_image_mask, cv2.DIST_L2, 3)\n",
    "        weight_map2 = cv2.distanceTransform(warped_mask, cv2.DIST_L2, 3)\n",
    "        \n",
    "        cv2.normalize(weight_map1, weight_map1, 0, 1, cv2.NORM_MINMAX)\n",
    "        cv2.normalize(weight_map2, weight_map2, 0, 1, cv2.NORM_MINMAX)\n",
    "        \n",
    "        # Blend overlapping regions\n",
    "        for y in range(panorama_height):\n",
    "            for x in range(panorama_width):\n",
    "                if overlap[y, x] > 0:\n",
    "                    w1 = weight_map1[y, x]\n",
    "                    w2 = weight_map2[y, x]\n",
    "                    weight_sum = w1 + w2\n",
    "                    \n",
    "                    if weight_sum > 0:\n",
    "                        w1 /= weight_sum\n",
    "                        w2 /= weight_sum\n",
    "                        \n",
    "                        for c in range(3):\n",
    "                            panorama[y, x, c] = np.uint8(\n",
    "                                panorama[y, x, c] * w1 + \n",
    "                                warped_img[y, x, c] * w2\n",
    "                            )\n",
    "                elif warped_mask[y, x] > 0:\n",
    "                    panorama[y, x] = warped_img[y, x]\n",
    "        \n",
    "        # Trim black borders\n",
    "        result = remove_black_borders(panorama)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stitch_images(images):\n",
    "    keypoints_descriptors = extract_keypoints(images)\n",
    "    return stitch_images_sequential(images, keypoints_descriptors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stitching image 2/6\n",
      "Stitching image 3/6\n",
      "Stitching image 4/6\n",
      "Stitching image 5/6\n",
      "Stitching image 6/6\n",
      "All outputs have been saved to the 'PanoOutputs' directory\n"
     ]
    }
   ],
   "source": [
    "image_files = sorted(glob.glob(\"PanoInputs2/*.jpg\"))\n",
    "images = []\n",
    "for f in image_files:\n",
    "    img = cv2.imread(f)\n",
    "    if img is not None:\n",
    "        images.append(img)\n",
    "    else:\n",
    "        print(f\"Warning: Could not load image {f}\")\n",
    "\n",
    "if len(images) < 2:\n",
    "    print(\"Not enough images to stitch.\")\n",
    "else:\n",
    "    # Resize images if they're too large\n",
    "    max_width = 1200\n",
    "    for i in range(len(images)):\n",
    "        h, w = images[i].shape[:2]\n",
    "        if w > max_width:\n",
    "            scale = max_width / w\n",
    "            images[i] = cv2.resize(images[i], None, fx=scale, fy=scale)\n",
    "    \n",
    "    # Stitch images\n",
    "    panorama = stitch_images(images)\n",
    "    \n",
    "    # Save the panorama\n",
    "    cv2.imwrite(\"PanoOutputs/NSOutput.jpg\", panorama)\n",
    "    \n",
    "    print(f\"All outputs have been saved to the 'PanoOutputs' directory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 number of images that need to be stiched into 1 image.\n"
     ]
    }
   ],
   "source": [
    "image_paths = glob.glob('PanoInputs2/*.jpg')\n",
    "images = []\n",
    "print(len(image_paths), \"number of images that need to be stiched into 1 image.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images Stiched successfully. Check folder named 'PanoOutputs'.\n"
     ]
    }
   ],
   "source": [
    "for image in image_paths:\n",
    "    img = cv2.imread(image)\n",
    "    images.append(img)\n",
    "    cv2.imshow(\"Image\", img)\n",
    "    cv2.waitKey(0)\n",
    "\n",
    "\n",
    "imageStitcher = cv2.Stitcher_create()\n",
    "\n",
    "error, stitched_img = imageStitcher.stitch(images)\n",
    "\n",
    "if not error:\n",
    "\n",
    "    cv2.imshow(\"Stitched Img\", stitched_img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    stitched_img = cv2.copyMakeBorder(stitched_img, 10, 10, 10, 10, cv2.BORDER_CONSTANT, (0,0,0))\n",
    "    gray = cv2.cvtColor(stitched_img, cv2.COLOR_BGR2GRAY)\n",
    "    thresh_img = cv2.threshold(gray, 0, 255 , cv2.THRESH_BINARY)[1]\n",
    "\n",
    "    cv2.imshow(\"Threshold Image\", thresh_img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    contours = cv2.findContours(thresh_img.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contours = imutils.grab_contours(contours)\n",
    "    areaOI = max(contours, key=cv2.contourArea)\n",
    "\n",
    "    mask = np.zeros(thresh_img.shape, dtype=\"uint8\")\n",
    "    x, y, w, h = cv2.boundingRect(areaOI)\n",
    "    cv2.rectangle(mask, (x,y), (x + w, y + h), 255, -1)\n",
    "\n",
    "    minRectangle = mask.copy()\n",
    "    sub = mask.copy()\n",
    "\n",
    "    while cv2.countNonZero(sub) > 0:\n",
    "        minRectangle = cv2.erode(minRectangle, None)\n",
    "        sub = cv2.subtract(minRectangle, thresh_img)\n",
    "\n",
    "\n",
    "    contours = cv2.findContours(minRectangle.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contours = imutils.grab_contours(contours)\n",
    "    areaOI = max(contours, key=cv2.contourArea)\n",
    "\n",
    "    cv2.imshow(\"minRectangle Image\", minRectangle)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    x, y, w, h = cv2.boundingRect(areaOI)\n",
    "    stitched_img = stitched_img[y:y + h, x:x + w]\n",
    "\n",
    "    cv2.imwrite(\"PanoOutputs/Output.png\", stitched_img)\n",
    "    cv2.imshow(\"Stitched Image Processed\", stitched_img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    print(\"Images Stiched successfully. Check folder named 'PanoOutputs'.\")\n",
    "else:\n",
    "    print(\"Images could not be stitched!\")\n",
    "    print(\"Likely not enough keypoints being detected!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
